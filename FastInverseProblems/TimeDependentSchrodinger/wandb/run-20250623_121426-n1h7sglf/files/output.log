Traceback (most recent call last):
  File "n:\PINN-RC\FastInverseProblems\TimeDependentSchrodinger\OfflineTrainingTests.py", line 368, in <module>
    Reservoir, averageLossOverTime = trainFullNetworkWithPrecomputing(Reservoir,data,(tscale),(xscale),outmodel,nummodels,ICs,LeftBoundary,RightBoundary,colocationPoints,ODEWeight,ICWeight,BCWeight,DataWeight,trainingEpochs,loss_fn,trainlr,averageLossOverTime,device,verbose=False)
  File "n:\PINN-RC\FastInverseProblems\TimeDependentSchrodinger\OfflineTrainingTests.py", line 203, in trainFullNetworkWithPrecomputing
    grad1 = torch.autograd.grad(
  File "C:\Users\smanor\AppData\Local\miniconda3\envs\PINN-RC\lib\site-packages\torch\autograd\__init__.py", line 502, in grad
    result = _engine_run_backward(
  File "C:\Users\smanor\AppData\Local\miniconda3\envs\PINN-RC\lib\site-packages\torch\autograd\graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
